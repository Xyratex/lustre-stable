Index: linux-2.6.32-220.7.1.el6.x86_64/drivers/md/raid5.c
===================================================================
--- linux-2.6.32-220.7.1.el6.x86_64.orig/drivers/md/raid5.c
+++ linux-2.6.32-220.7.1.el6.x86_64/drivers/md/raid5.c
@@ -193,6 +193,25 @@ static int stripe_operations_active(stru
 	       test_bit(STRIPE_COMPUTE_RUN, &sh->state);
 }
 
+static struct page *zero_copy_data(struct bio *bio, sector_t sector)
+{
+	sector_t bi_sector = bio->bi_sector;
+	struct page *page = NULL;
+	struct bio_vec *bvl;
+	int i;
+
+	bio_for_each_segment(bvl, bio, i) {
+		if (sector == bi_sector && bvl->bv_len == STRIPE_SIZE) {
+			page = bvl->bv_page;
+			if (PageConstant(page))
+				return page;
+			return NULL;
+		}
+		bi_sector += bvl->bv_len >> 9;
+	}
+	return NULL;
+}
+
 static void __release_stripe(raid5_conf_t *conf, struct stripe_head *sh)
 {
 	if (atomic_dec_and_test(&sh->count)) {
@@ -495,6 +514,26 @@ raid5_end_read_request(struct bio *bi, i
 static void
 raid5_end_write_request(struct bio *bi, int error);
 
+static inline void r5dev_switch_page(struct r5dev *dev, struct page *page)
+{
+	BUG_ON(dev->page_save != NULL);
+	BUG_ON(dev->page != bio_iovec_idx(&dev->req, 0)->bv_page);
+	/* The pointer must be restored whenever the LOCKED gets cleared. */
+	dev->page_save = dev->page;
+	dev->page = bio_iovec_idx(&dev->req, 0)->bv_page = page;
+	kmap(dev->page); /* for sync_xor on 32-bit systems */
+}
+
+static inline void r5dev_restore_page(struct r5dev *dev)
+{
+	BUG_ON(dev->page_save == NULL);
+	BUG_ON(dev->page != bio_iovec_idx(&dev->req, 0)->bv_page);
+	BUG_ON(dev->page == dev->page_save);
+	kunmap(dev->page_save);
+	dev->page = bio_iovec_idx(&dev->req, 0)->bv_page = dev->page_save;
+	dev->page_save = NULL;
+}
+
 static void ops_run_io(struct stripe_head *sh, struct stripe_head_state *s)
 {
 	raid5_conf_t *conf = sh->raid_conf;
@@ -563,6 +602,10 @@ static void ops_run_io(struct stripe_hea
 				set_bit(STRIPE_DEGRADED, &sh->state);
 			pr_debug("skip op %ld on disc %d for sector %llu\n",
 				bi->bi_rw, i, (unsigned long long)sh->sector);
+
+			if (test_bit(R5_Direct, &sh->dev[i].flags))
+				r5dev_restore_page(&sh->dev[i]);
+
 			clear_bit(R5_LOCKED, &sh->dev[i].flags);
 			set_bit(STRIPE_HANDLE, &sh->state);
 		}
@@ -1009,6 +1052,33 @@ ops_run_prexor(struct stripe_head *sh, s
 	return tx;
 }
 
+static int try_reuse_data_page(struct r5dev *dev)
+{
+	struct bio *wbi = dev->written;
+	struct page *page;
+	sector_t sector = dev->sector;
+
+	BUG_ON(!test_bit(R5_LOCKED, &dev->flags));
+	BUG_ON(test_bit(R5_Direct, &dev->flags));
+
+	/* check if it's covered by a single page
+	   and the whole stripe is written at once.
+	 * in this case we can avoid memcpy() */
+	if (wbi && !wbi->bi_next && test_bit(R5_OVERWRITE, &dev->flags) &&
+	    test_bit(R5_Insync, &dev->flags)) {
+		page = zero_copy_data(wbi, sector);
+		if (page) {
+			set_bit(R5_Direct, &dev->flags);
+			r5dev_switch_page(dev, page);
+			clear_bit(R5_UPTODATE, &dev->flags);
+			clear_bit(R5_OVERWRITE, &dev->flags);
+			return 1;
+		}
+	}
+
+	return 0;
+}
+
 static struct dma_async_tx_descriptor *
 ops_run_biodrain(struct stripe_head *sh, struct dma_async_tx_descriptor *tx)
 {
@@ -1032,6 +1102,13 @@ ops_run_biodrain(struct stripe_head *sh,
 			wbi = dev->written = chosen;
 			spin_unlock(&sh->lock);
 
+			if (try_reuse_data_page(dev)) {
+				if (wbi->bi_rw & REQ_FUA)
+					set_bit(R5_WantFUA, &dev->flags);
+				atomic_inc(&sh->raid_conf->writes_zcopy);
+				continue;
+			}
+
 			while (wbi && wbi->bi_sector <
 				dev->sector + STRIPE_SECTORS) {
 				if (wbi->bi_rw & BIO_FUA)
@@ -1065,7 +1142,8 @@ static void ops_complete_reconstruct(voi
 		struct r5dev *dev = &sh->dev[i];
 
 		if (dev->written || i == pd_idx || i == qd_idx) {
-			set_bit(R5_UPTODATE, &dev->flags);
+			if (!test_bit(R5_Direct, &dev->flags))
+				set_bit(R5_UPTODATE, &dev->flags);
 			if (fua)
 				set_bit(R5_WantFUA, &dev->flags);
 		}
@@ -1642,6 +1720,7 @@ static void raid5_end_read_request(struc
 		}
 	}
 	rdev_dec_pending(conf->disks[i].rdev, conf->mddev);
+	BUG_ON(bio_iovec_idx(&sh->dev[i].req, 0)->bv_page != sh->dev[i].page);
 	clear_bit(R5_LOCKED, &sh->dev[i].flags);
 	set_bit(STRIPE_HANDLE, &sh->state);
 	release_stripe(sh);
@@ -1671,6 +1750,8 @@ static void raid5_end_write_request(stru
 
 	rdev_dec_pending(conf->disks[i].rdev, conf->mddev);
 	
+	if (test_bit(R5_Direct, &sh->dev[i].flags))
+		r5dev_restore_page(&sh->dev[i]);
 	clear_bit(R5_LOCKED, &sh->dev[i].flags);
 	set_bit(STRIPE_HANDLE, &sh->state);
 	release_stripe(sh);
@@ -2511,7 +2592,8 @@ static void handle_stripe_clean_event(ra
 		if (sh->dev[i].written) {
 			dev = &sh->dev[i];
 			if (!test_bit(R5_LOCKED, &dev->flags) &&
-				test_bit(R5_UPTODATE, &dev->flags)) {
+				(test_bit(R5_UPTODATE, &dev->flags) ||
+				 test_bit(R5_Direct, &dev->flags))) {
 				/* We can return any write requests */
 				struct bio *wbi, *wbi2;
 				int bitmap_end = 0;
@@ -2519,6 +2601,7 @@ static void handle_stripe_clean_event(ra
 				spin_lock_irq(&conf->device_lock);
 				wbi = dev->written;
 				dev->written = NULL;
+				clear_bit(R5_Direct, &dev->flags);
 				while (wbi && wbi->bi_sector <
 					dev->sector + STRIPE_SECTORS) {
 					wbi2 = r5_next_bio(wbi, dev->sector);
@@ -3472,7 +3555,8 @@ static void handle_stripe6(struct stripe
 			    (i == sh->pd_idx || i == qd_idx ||
 			     dev->written)) {
 				pr_debug("Writing block %d\n", i);
-				BUG_ON(!test_bit(R5_UPTODATE, &dev->flags));
+				BUG_ON(!test_bit(R5_UPTODATE, &dev->flags) &&
+				       !test_bit(R5_Direct, &dev->flags));
 				set_bit(R5_Wantwrite, &dev->flags);
 				if (!test_bit(R5_Insync, &dev->flags) ||
 				    ((i == sh->pd_idx || i == qd_idx) &&
@@ -5206,6 +5290,7 @@ static int run(mddev_t *mddev)
 
 		mddev->queue->backing_dev_info.congested_data = mddev;
 		mddev->queue->backing_dev_info.congested_fn = raid5_congested;
+		mddev->queue->backing_dev_info.capabilities |= BDI_CAP_PAGE_CONSTANT_WRITE;
 		mddev->queue->unplug_fn = raid5_unplug_queue;
 
 		chunk_size = mddev->chunk_sectors << 9;
Index: linux-2.6.32-220.7.1.el6.x86_64/drivers/md/raid5.h
===================================================================
--- linux-2.6.32-220.7.1.el6.x86_64.orig/drivers/md/raid5.h
+++ linux-2.6.32-220.7.1.el6.x86_64/drivers/md/raid5.h
@@ -232,7 +232,7 @@ struct stripe_head {
 	struct r5dev {
 		struct bio	req;
 		struct bio_vec	vec;
-		struct page	*page;
+		struct page	*page, *page_save;
 		struct bio	*toread, *read, *towrite, *written;
 		sector_t	sector;			/* sector of this page */
 		unsigned long	flags;
@@ -276,6 +276,9 @@ struct r6_state {
 				    */
 #define R5_Wantdrain	13 /* dev->towrite needs to be drained */
 #define R5_WantFUA	14	/* Write should be FUA */
+
+#define	R5_Direct	31	/* Use the pages in bio to do the write directly. */
+
 /*
  * Write method
  */
Index: linux-2.6.32-220.7.1.el6.x86_64/include/linux/backing-dev.h
===================================================================
--- linux-2.6.32-220.7.1.el6.x86_64.orig/include/linux/backing-dev.h
+++ linux-2.6.32-220.7.1.el6.x86_64/include/linux/backing-dev.h
@@ -230,6 +230,7 @@ int bdi_set_max_ratio(struct backing_dev
 #define BDI_CAP_EXEC_MAP	0x00000040
 #define BDI_CAP_NO_ACCT_WB	0x00000080
 #define BDI_CAP_SWAP_BACKED	0x00000100
+#define BDI_CAP_PAGE_CONSTANT_WRITE	0x00000200	/* Zcopy write - for raid5 */
 
 #define BDI_CAP_VMFLAGS \
 	(BDI_CAP_READ_MAP | BDI_CAP_WRITE_MAP | BDI_CAP_EXEC_MAP)
@@ -304,6 +305,11 @@ static inline bool bdi_cap_swap_backed(s
 	return bdi->capabilities & BDI_CAP_SWAP_BACKED;
 }
 
+static inline bool bdi_cap_page_constant_write(struct backing_dev_info *bdi)
+{
+	return bdi->capabilities & BDI_CAP_PAGE_CONSTANT_WRITE;
+}
+
 static inline bool bdi_cap_flush_forker(struct backing_dev_info *bdi)
 {
 	return bdi == &default_backing_dev_info;
@@ -324,6 +330,10 @@ static inline bool mapping_cap_swap_back
 	return bdi_cap_swap_backed(mapping->backing_dev_info);
 }
 
+static inline bool mapping_cap_page_constant_write(struct address_space *mapping) {
+	return bdi_cap_page_constant_write(mapping->backing_dev_info);
+}
+
 static inline int bdi_sched_wait(void *word)
 {
 	schedule();
Index: linux-2.6.32-220.7.1.el6.x86_64/include/linux/page-flags.h
===================================================================
--- linux-2.6.32-220.7.1.el6.x86_64.orig/include/linux/page-flags.h
+++ linux-2.6.32-220.7.1.el6.x86_64/include/linux/page-flags.h
@@ -111,6 +111,9 @@ enum pageflags {
 #ifdef CONFIG_TRANSPARENT_HUGEPAGE
 	PG_compound_lock,
 #endif
+#ifdef CONFIG_SUPPORT_PG_CONSTANT_FLAG
+	PG_constant,
+#endif
 	__NR_PAGEFLAGS,
 
 	/* Filesystems */
@@ -285,6 +288,12 @@ PAGEFLAG_FALSE(HWPoison)
 #define __PG_HWPOISON 0
 #endif
 
+#ifdef CONFIG_SUPPORT_PG_CONSTANT_FLAG
+PAGEFLAG(Constant,constant)
+#else
+PAGEFLAG_FALSE(Constant)
+#endif
+
 u64 stable_page_flags(struct page *page);
 
 static inline int PageUptodate(struct page *page)
Index: linux-2.6.32-220.7.1.el6.x86_64/drivers/md/Kconfig
===================================================================
--- linux-2.6.32-220.7.1.el6.x86_64.orig/drivers/md/Kconfig
+++ linux-2.6.32-220.7.1.el6.x86_64/drivers/md/Kconfig
@@ -352,4 +352,11 @@ config DM_FLAKEY
        ---help---
          A target that intermittently fails I/O for debugging purposes.
 
+config SUPPORT_PG_CONSTANT_FLAG
+       bool "Enable page flag for RAID5 zero copy support (EXPERIMENTAL)"
+       default n
+       ---help---
+        Enable support for page flag to support 
+        Raid 5 Zero copy on the Lustre File system.
+
 endif # MD
